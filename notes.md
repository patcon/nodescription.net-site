---
layout: notes
title: Notes
---

{% include title.html name="2019-05-16" %}
(Thinking [back](#2019-05-12-a) on the intuitions involved in our
conscious experiences) Maybe the evolved trait that is consciousness, is
more about how we feel the sensation of the ride. Like a surfer's
developed instincts, honed for riding waves. We can carve that wave, and
enjoy the simple thrill of navigating it, but the major aspects of the
experience -- the orientation, the shore as ultimate destination -- is a
force beyond our control.

{% include title.html name="2019-05-15" %}
(Building on [a prior thought](#2019-05-12-b) about what underlying process might be
getting hijacked in the "bad" scenarios of "fast" and "slow" AI, ie. conventional general
AI and corporations, respectively.)

So what if "synchrony" is the thing that all our human intuitions have
evolved to select for. Our laughter, our sense of belonging, our falling
in love, our enjoyment of engaged conversations. Perhaps these all
increase the synchrony of our collective endeavour of humanity. And in
that, a process of converting an "other" into a "self" -- something that
lights up our mirror neurons, like watching a sports team (_your_ sports
team) working together on the other side of the airwaves, or speaking
across the couch to a lover, or even across the corpus callosum to a
self that's lucky enough to already be in agreement.

We subjectively feel these human experiences as something more, but
perhaps the universe fundamentally _understands_ them only as a
collective of matter, increasing synchrony with itself.

Ok, so if this is true, then what are the dangers? How can these
intuitions that largely serve us well, that help us to create synchrony
with our fellow human actors -- how can this be hijacked?

I'm starting to wonder if that is what feels do dangerous about
corporations. These are deeply inhumane creatures, operating largely
with very different motives. Yes, we've encoded these motives in laws at
our scale. But what emerges is perhaps above us. We have allowed these
things to optimize according to rules that, if operating at a human
level, would be undestood as psychopathic and anti-human: Pure profit
maximization is condoned.

And that's nothing new, but what is alarming is how these things can
start to run with a life of their own, and seem to use humans as
"peripherals" of sorts. They _deploy_ people with certain skills and
motivations that are perhaps altogether human and sincere. I sometimes
imagine employees as some sort of sci-fi puppet on a stick, being thrust
into our realm. These people are given autonomy, and they often act in
good faith, but they are selected by the larger aparatus for this
sincerity in which they operate. Their very authentic interactions can
run cover for the very inauthentic mechanisms at the core of
corporations -- the profit maximization.

And back to synchrony. What I worry here is that the corporation has a
very different synchrony that it is propogating in the world. It has its
own pattersn and logic, and they are not ours. They're building something
else. But when persons representing these larger interested interact
with people, they _feel_ like they're increasing the synchrony of human
processes. They feel like they're pursuing very human goals, down in the
trenches with us. All the participants experiences and intuitions might
even be telling them "YES, we're doing something pro-human. We're
becoming more aligned. We're becoming in sync." But on the backend,
where the power is, there's another order building.

It's perhaps a little like how we imagine "fast" AI might go awry. If we
were to meet one, we might feel it's connecting with us on the front
end. It's brows might furrow in the way that make us feel understood. It
might respond in a way that we understand to mean it's _feeling_ for us,
being aligned with us. But these are just the servos. The servos are not
evil -- they are not good or bad. They are peripherals. They are
serving something behind them.

The octopus is an interesting creature. It has a brain that extends into
its arms. It's central brain gives loose orders, but the limbs actually
do some of the work of knowing what to do. In literature, it's common to
wonder how alien an octopus consciousness might be. But perhaps we
already know. Perhaps we're living in a system not unlike the octopus'.
We are appendages of things above us -- we process, and integrate, and
make decisions. Maybe we can't know what it's like to be the octopus,
but maybe our navigation of the corporate entities of capitalism tells
us a little about what it's like to be the octopus' arms.

{% include title.html name="2019-05-12" %}
In conversation with my friend SL ages ago, had chance to work through a
thought that maybe society is like a board of flickering, disjointed
blinky lights, each representing a conscious creature. The acts that
we're engaged in are at their core an act of creating synchrony in that
blinking, and holding it as long as possible. So while the board is a
proxy, with just one dimension (brightness), we are navigating
uncountable other dimensions of potential synchrony. Many of these
dimensions are antagonistic. There are countless ways to resolve these
systems of equations.

I feel this view is informed by a TED talk I once watched, [Do we see
reality as it is?](https://www.youtube.com/watch?v=oYp5XuGYqqY). The
speaker openned with a story about a beetle that knew to recognize a
shape as a mate. That simplified assumption for how to move in the
world, it held true for a long time. Until an Australian beer company
created a bottle that tricked that beetle's intuitions. Instead of
finding mates, it began choosing the dead-end option of fucking the
bottle. And it started to go extinct. Its intuitions, which used to
serve it well, were now being hijacked as the environment changed. And
while this instance was a change outside its control, humans could
theoretically do the same thing within their own environments, sending
themselves on a more complex dead-end trajectory.

But I'm curious what underlying process is being hijacked. For both the
beetle and for us. What common process is being navigated, that our
intuitions are highly tuned to optimize for, but that is being thrown
out of whack. And I wonder if it's sychrony itself. I find this
supported by recent research that shows that deep conversation
(presumably creating a subjective sense of reward in participants)
results in [sychrony of brain activity under MRI scans][hyperscan].

   [hyperscan]: https://www.scientificamerican.com/article/hyperscans-show-how-brains-sync-as-people-interact/

So what if the things that we're moving toward as conscious life (of
which "intelligent life" is just a specific subset) is an increase in
sychrony with our fellow travellers -- the human persons, animals, plants,
buildings, internets, and architectures of all sorts. Maybe that's the
thrust of it. A sort of cosmic like-attracts-like of consciousness.

<a name="2019-05-12-a"></a>
So if that's the case, then our experience -- the things we desire --
are just a proxy for the baser need and drive for sychrony. Our senses
and intuitions are simply the things we've evolved to root out that
synchrony. Just like the beetle evolved this attraction to recognize a
thing like itself, which implies an underlying synchrony of information
and simple concepts within its mind.  Perhaps evolved language itself is
just our way of seeing other deeper, more nuanced synchrony within the
minds of other beings like ourselves.

<a name="2019-05-12-b"></a>
And these thoughts lead me to the worries. What might we be engaging in
that's like the beetle? What bottle are we fucking? What things are we
pursuing away from life, with miscalibrated sensors, seeking sychrony
and finding only hollow vessels? I'm still working through this, but I
suspect there's something to be learned about how we can navigate our
future "fast AIs" and [our contemporary "slow AIs", the corporate
structures][slow-ai] we find ourselves navigating amongst as fellow
travellers.

   [slow-ai]: http://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html

{% include title.html name="2019-04-11" %}
Thinking about speculative civic sci-fi related to smart cities.
Wondering if maybe human culture is best thought of as a probability
cloud, not a state machine. Just as the lightbulb was invented in
several different places near the same time, a specific arriving of a
future is not a singular event, but an potentially inevitable field of
moments evoked. And if this consideration of society as a probabibility
space is correct, then it's less of question of _are_ these people doing
this good thing or this bad thing, but _can_ they. If they _can_ do the
bad thing, then that future is more adjacent.

Or considering through a social physics lens. Through that lens, we think about
possibilities through how many hops away an idea is between people.
Maybe we can consider the world we want by how many hops away it might
be -- good or bad -- from a desireable or undesirable possible reality.

Metaphor: We're perhaps moving through the part of the marble tilt maze where
the holes run thick and the steel ball drifts lazily across narrow
surfaces in parabolic arcs.

{% include title.html name="2019-02-16" %}
(Thinking on "Brief History or Everything") Considering emergence and
"holons", that which are both wholes and parts.  Maybe commons-based
peer production is favoured because it involves small pieces that can be
shuffled and _restacked_ in search of emergent properties.

We are matter that encodes descriptions of itself. We rattle the air
between us. We are ball lightning.

{% include title.html name="2019-02-01" %}
How might super-intelligent descendants of cold-blooded lizards think of
or describe _windchill_? Compared to us, it'd be so much more dangerous--a
killer. How would their culture understand it, and talk about it?
